{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a1352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hotson/kaggle_work/csiro-biomass/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hotson/kaggle_work/csiro-biomass/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fold 0 inference:   0%|          | 0/17 [00:00<?, ?it/s]_rows=67]\n",
      "Folds:   0%|          | 0/5 [00:09<?, ?it/s, fold=0, val_rows=67]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_50569/330029836.py\", line 52, in __getitem__\n    with open(img_path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 344, in _modified_open\n    return io_open(file, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: './train/ID1035947949.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 231\u001b[39m\n\u001b[32m    216\u001b[39m per_fold_model_mapping = {\n\u001b[32m    217\u001b[39m     \u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/2776e2c07fd544d79afcbfff8db8f429/artifacts/fold_0_best/DinoV3Hybrid_fold0.pt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    218\u001b[39m     \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/6a52b6a027b74fc0b65234a84fe50cc8/artifacts/fold_1_best/DinoV3Hybrid_fold1.pt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     \u001b[32m4\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/9d36bdbc10ac4bdc839eefab5d24409a/artifacts/fold_4_best/DinoV3Hybrid_fold4.pt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m }\n\u001b[32m    223\u001b[39m per_fold_val_mapping = {\n\u001b[32m    224\u001b[39m     \u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold0.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m     \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold1.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m     \u001b[32m4\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold4.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    229\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m oof_pred_df, oof_true_df = \u001b[43mbuild_oof_csvs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_fold_model_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_fold_model_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_fold_val_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_fold_val_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvit_huge_plus_patch16_dinov3.lvd1689m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./oof/dinov3_mamba_hybrid_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mbuild_oof_csvs\u001b[39m\u001b[34m(per_fold_model_mapping, per_fold_val_mapping, img_dir, model_id, img_size, batch_size, num_workers, out_dir)\u001b[39m\n\u001b[32m    173\u001b[39m loader = DataLoader(\n\u001b[32m    174\u001b[39m     ds,\n\u001b[32m    175\u001b[39m     batch_size=batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    180\u001b[39m )\n\u001b[32m    182\u001b[39m model = load_hybrid_from_ckpt(ckpt_path, device=device, model_id=model_id)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m pred_rows, true_rows = \u001b[43minfer_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# add fold column\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m pred_rows:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36minfer_one_fold\u001b[39m\u001b[34m(model, loader, device, fold)\u001b[39m\n\u001b[32m     77\u001b[39m rows_true = []\n\u001b[32m     79\u001b[39m pbar = tqdm(\n\u001b[32m     80\u001b[39m     loader,\n\u001b[32m     81\u001b[39m     desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inference\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m     dynamic_ncols=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     83\u001b[39m     leave=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     84\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1516\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1514\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1515\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1551\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle_work/.venv/lib/python3.12/site-packages/torch/_utils.py:769\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_50569/330029836.py\", line 52, in __getitem__\n    with open(img_path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hotson/kaggle_work/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 344, in _modified_open\n    return io_open(file, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: './train/ID1035947949.jpg'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "from models.dinov3_mamba_2_tiles import DinoV3Hybrid, DinoV3HybridConfig\n",
    "\n",
    "TARGETS = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset (val only)\n",
    "# -----------------------------\n",
    "class CSIRODataset(Dataset):\n",
    "    def __init__(self, df, img_dir, img_size):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.S = int(img_size)\n",
    "\n",
    "        self.H = self.S * 2\n",
    "        self.W = self.S * 4\n",
    "\n",
    "        self.aug = A.Compose(\n",
    "            [\n",
    "                A.Resize(self.H, self.W),\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        y = torch.tensor(\n",
    "            row[TARGETS].to_numpy(dtype=\"float32\", na_value=0.0),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        rel_path = str(row[\"image_path\"])\n",
    "        img_path = rel_path if os.path.isabs(rel_path) else os.path.join(self.img_dir, rel_path)\n",
    "\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            img = np.array(Image.open(f).convert(\"RGB\"))\n",
    "\n",
    "        img_t = self.aug(image=img)[\"image\"]  # (3, H, W)\n",
    "        return img_t, y, rel_path\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model loader\n",
    "# -----------------------------\n",
    "def load_hybrid_from_ckpt(ckpt_path: str, device: torch.device, model_id: str):\n",
    "    cfg = DinoV3HybridConfig(model_id=model_id)\n",
    "    model = DinoV3Hybrid(cfg).to(device)\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    state = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
    "    model.load_state_dict(state, strict=True)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_one_fold(model, loader, device, fold: int):\n",
    "    rows_pred = []\n",
    "    rows_true = []\n",
    "\n",
    "    pbar = tqdm(\n",
    "        loader,\n",
    "        desc=f\"Fold {fold} inference\",\n",
    "        dynamic_ncols=True,\n",
    "        leave=True,\n",
    "    )\n",
    "\n",
    "    for x, y, rel_path in pbar:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        # Split full image into left/right for DinoV3Hybrid\n",
    "        _, _, _, W = x.shape\n",
    "        mid = W // 2\n",
    "        left = x[:, :, :, :mid]\n",
    "        right = x[:, :, :, mid:]\n",
    "\n",
    "        out = model(left, right)\n",
    "\n",
    "        pred5 = out[\"pred5\"].detach().float().cpu().numpy()  # (B,5)\n",
    "        y5 = y.detach().float().cpu().numpy()\n",
    "\n",
    "        # optional ratio columns\n",
    "        dead_ratio = out.get(\"dead_ratio_pred\", None)\n",
    "        clov_ratio = out.get(\"clover_ratio_pred\", None)\n",
    "        if dead_ratio is not None:\n",
    "            dead_ratio = dead_ratio.detach().float().cpu().numpy()\n",
    "        if clov_ratio is not None:\n",
    "            clov_ratio = clov_ratio.detach().float().cpu().numpy()\n",
    "\n",
    "        # write rows\n",
    "        for i in range(pred5.shape[0]):\n",
    "            sample_id = Path(rel_path[i]).stem\n",
    "\n",
    "            # true row\n",
    "            tr = {\"sample_id\": sample_id, \"image_path\": rel_path[i]}\n",
    "            for j, t in enumerate(TARGETS):\n",
    "                tr[t] = float(y5[i, j])\n",
    "            rows_true.append(tr)\n",
    "\n",
    "            # pred row\n",
    "            pr = {\"sample_id\": sample_id, \"image_path\": rel_path[i]}\n",
    "            for j, t in enumerate(TARGETS):\n",
    "                pr[t] = float(pred5[i, j])\n",
    "\n",
    "            if dead_ratio is not None:\n",
    "                pr[\"dead_ratio_pred\"] = float(dead_ratio[i])\n",
    "            if clov_ratio is not None:\n",
    "                pr[\"clover_ratio_pred\"] = float(clov_ratio[i])\n",
    "\n",
    "            rows_pred.append(pr)\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            rows=len(rows_pred),\n",
    "            bs=pred5.shape[0],\n",
    "        )\n",
    "\n",
    "    return rows_pred, rows_true\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN OOF LOOP\n",
    "# -----------------------------\n",
    "def build_oof_csvs(\n",
    "    per_fold_model_mapping: dict,\n",
    "    per_fold_val_mapping: dict,\n",
    "    img_dir: str,\n",
    "    model_id: str,\n",
    "    img_size: int = 512,\n",
    "    batch_size: int = 8,\n",
    "    num_workers: int = 4,\n",
    "    out_dir: str = \"./oof\",\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "\n",
    "    folds = sorted(per_fold_model_mapping.keys())\n",
    "    fold_pbar = tqdm(folds, desc=\"Folds\", dynamic_ncols=True, leave=True)\n",
    "\n",
    "    for fold in fold_pbar:\n",
    "        ckpt_path = per_fold_model_mapping[fold]\n",
    "        val_csv = per_fold_val_mapping[fold]\n",
    "\n",
    "        df_val = pd.read_csv(val_csv)\n",
    "\n",
    "        fold_pbar.set_postfix(\n",
    "            fold=fold,\n",
    "            val_rows=len(df_val),\n",
    "        )\n",
    "\n",
    "        ds = CSIRODataset(df_val, img_dir=img_dir, img_size=img_size)\n",
    "        loader = DataLoader(\n",
    "            ds,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = load_hybrid_from_ckpt(ckpt_path, device=device, model_id=model_id)\n",
    "\n",
    "        pred_rows, true_rows = infer_one_fold(model, loader, device=device, fold=fold)\n",
    "\n",
    "        # add fold column\n",
    "        for r in pred_rows:\n",
    "            r[\"fold\"] = fold\n",
    "        for r in true_rows:\n",
    "            r[\"fold\"] = fold\n",
    "\n",
    "        all_pred.extend(pred_rows)\n",
    "        all_true.extend(true_rows)\n",
    "\n",
    "        # free memory between folds\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    oof_pred = pd.DataFrame(all_pred)\n",
    "    oof_true = pd.DataFrame(all_true)\n",
    "\n",
    "    # oof_pred_path = os.path.join(out_dir, \"oof_pred.csv\")\n",
    "    # oof_true_path = os.path.join(out_dir, \"oof_true.csv\")\n",
    "\n",
    "    # oof_pred.to_csv(oof_pred_path, index=False)\n",
    "    # oof_true.to_csv(oof_true_path, index=False)\n",
    "\n",
    "    # print(\"\\nSaved:\")\n",
    "    # print(oof_pred_path)\n",
    "    # print(oof_true_path)\n",
    "\n",
    "    return oof_pred, oof_true\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    per_fold_model_mapping = {\n",
    "        0: \"/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/2776e2c07fd544d79afcbfff8db8f429/artifacts/fold_0_best/DinoV3Hybrid_fold0.pt\",\n",
    "        1: \"/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/6a52b6a027b74fc0b65234a84fe50cc8/artifacts/fold_1_best/DinoV3Hybrid_fold1.pt\",\n",
    "        2: \"/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/b3a849cab7954bf5a98e62ab3d60964f/artifacts/fold_2_best/DinoV3Hybrid_fold2.pt\",\n",
    "        3: \"/home/hotson/kaggle_work/csiro-biomass/mlruns/801380342288325569/9567cd0f28af4b8d9d407df1c30ddb1d/artifacts/fold_3_best/DinoV3Hybrid_fold3.pt\",\n",
    "        4: \"/home/hotson/kaggle_work/csiro-biomass/mlruns/612035296614314672/7085174f4dc9463f9ee7c349453368e1/artifacts/fold_4_best/DinoV3Hybrid_fold4.pt\",\n",
    "    }\n",
    "    per_fold_val_mapping = {\n",
    "        0: \"/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold0.csv\",\n",
    "        1: \"/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold1.csv\",\n",
    "        2: \"/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold2.csv\",\n",
    "        3: \"/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold3.csv\",\n",
    "        4: \"/home/hotson/kaggle_work/csiro-biomass/exps/splits/csiro_folds_5/val_fold4.csv\",\n",
    "    }\n",
    "\n",
    "    oof_pred_df, oof_true_df = build_oof_csvs(\n",
    "        per_fold_model_mapping=per_fold_model_mapping,\n",
    "        per_fold_val_mapping=per_fold_val_mapping,\n",
    "        img_dir=\".\",\n",
    "        model_id=\"vit_huge_plus_patch16_dinov3.lvd1689m\",\n",
    "        img_size=512,\n",
    "        batch_size=4,\n",
    "        num_workers=4,\n",
    "        out_dir=\"./oof/dinov3_mamba_hybrid_model\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc10373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
