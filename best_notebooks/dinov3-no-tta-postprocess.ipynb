{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05943d1d",
   "metadata": {
    "papermill": {
     "duration": 0.003929,
     "end_time": "2026-01-18T05:24:55.908289",
     "exception": false,
     "start_time": "2026-01-18T05:24:55.904360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSIRO Biomass Prediction - Inference Notebook\n",
    "\n",
    "This notebook performs inference using trained models, loading one model at a time to conserve memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923172b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:24:55.915931Z",
     "iopub.status.busy": "2026-01-18T05:24:55.915275Z",
     "iopub.status.idle": "2026-01-18T05:25:00.724905Z",
     "shell.execute_reply": "2026-01-18T05:25:00.724072Z"
    },
    "papermill": {
     "duration": 4.815436,
     "end_time": "2026-01-18T05:25:00.726789",
     "exception": false,
     "start_time": "2026-01-18T05:24:55.911353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: timm 1.0.19\r\n",
      "Uninstalling timm-1.0.19:\r\n",
      "  Successfully uninstalled timm-1.0.19\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y timm\n",
    "!pip install -q --no-deps /kaggle/input/wheels-csiro/timm-1.0.22-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4092e301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:00.734244Z",
     "iopub.status.busy": "2026-01-18T05:25:00.734003Z",
     "iopub.status.idle": "2026-01-18T05:25:15.150035Z",
     "shell.execute_reply": "2026-01-18T05:25:15.149133Z"
    },
    "papermill": {
     "duration": 14.421094,
     "end_time": "2026-01-18T05:25:15.151219",
     "exception": false,
     "start_time": "2026-01-18T05:25:00.730125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import gc\n",
    "\n",
    "SEED = 42\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10ae684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.158904Z",
     "iopub.status.busy": "2026-01-18T05:25:15.158507Z",
     "iopub.status.idle": "2026-01-18T05:25:15.162661Z",
     "shell.execute_reply": "2026-01-18T05:25:15.162071Z"
    },
    "papermill": {
     "duration": 0.009204,
     "end_time": "2026-01-18T05:25:15.163783",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.154579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TARGETS = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    MAX_SPECIES_LEN = 5\n",
    "    DATA_DIR = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    MODEL_DIR = Path(\"/kaggle/input/biomass-model-dinov3\")\n",
    "    IMG_SIZE = 512\n",
    "    N_FOLDS = 4\n",
    "    BACKBONE = \"vit_huge_plus_patch16_dinov3.lvd1689m\"\n",
    "    BATCH_SIZE = 2  # Can increase if memory allows\n",
    "    \n",
    "    # TTA configuration\n",
    "    USE_TTA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb320f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.170872Z",
     "iopub.status.busy": "2026-01-18T05:25:15.170424Z",
     "iopub.status.idle": "2026-01-18T05:25:15.212475Z",
     "shell.execute_reply": "2026-01-18T05:25:15.211730Z"
    },
    "papermill": {
     "duration": 0.046883,
     "end_time": "2026-01-18T05:25:15.213671",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.166788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 1785\n",
      "Test rows: 5\n",
      "\n",
      "Test data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Total_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>GDM_g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id             image_path   target_name\n",
       "0  ID1001187975__Dry_Clover_g  test/ID1001187975.jpg  Dry_Clover_g\n",
       "1    ID1001187975__Dry_Dead_g  test/ID1001187975.jpg    Dry_Dead_g\n",
       "2   ID1001187975__Dry_Green_g  test/ID1001187975.jpg   Dry_Green_g\n",
       "3   ID1001187975__Dry_Total_g  test/ID1001187975.jpg   Dry_Total_g\n",
       "4         ID1001187975__GDM_g  test/ID1001187975.jpg         GDM_g"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(CFG.DATA_DIR / \"train.csv\")\n",
    "test_df = pd.read_csv(CFG.DATA_DIR / \"test.csv\")\n",
    "\n",
    "print(f\"Train rows: {len(train_df)}\")\n",
    "print(f\"Test rows: {len(test_df)}\")\n",
    "print(\"\\nTest data preview:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd156a",
   "metadata": {
    "papermill": {
     "duration": 0.003436,
     "end_time": "2026-01-18T05:25:15.220864",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.217428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Test Data with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54cc6efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.228970Z",
     "iopub.status.busy": "2026-01-18T05:25:15.228410Z",
     "iopub.status.idle": "2026-01-18T05:25:15.242729Z",
     "shell.execute_reply": "2026-01-18T05:25:15.242186Z"
    },
    "papermill": {
     "duration": 0.019485,
     "end_time": "2026-01-18T05:25:15.243739",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.224254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data prepared: 1 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path\n",
       "0  test/ID1001187975.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wide = test_df[[\"image_path\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Test data prepared: {len(test_wide)} samples\")\n",
    "test_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28886fc7",
   "metadata": {
    "papermill": {
     "duration": 0.003254,
     "end_time": "2026-01-18T05:25:15.250337",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.247083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c901ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.258215Z",
     "iopub.status.busy": "2026-01-18T05:25:15.258031Z",
     "iopub.status.idle": "2026-01-18T05:25:15.268022Z",
     "shell.execute_reply": "2026-01-18T05:25:15.267438Z"
    },
    "papermill": {
     "duration": 0.015018,
     "end_time": "2026-01-18T05:25:15.268951",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.253933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalMambaBlock(nn.Module):\n",
    "    \"\"\"Lightweight Mamba-like block\"\"\"\n",
    "\n",
    "    def __init__(self, dim: int, kernel_size: int = 5, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dwconv = nn.Conv1d(dim, dim, kernel_size=kernel_size,\n",
    "                                 padding=kernel_size // 2, groups=dim)\n",
    "        self.gate = nn.Linear(dim, dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shortcut = x\n",
    "        x = self.norm(x)\n",
    "        g = torch.sigmoid(self.gate(x))\n",
    "        x = x * g\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.dwconv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        x = self.drop(x)\n",
    "        return shortcut + x\n",
    "\n",
    "\n",
    "class BiomassModel(nn.Module):\n",
    "    \"\"\"DINOv3 + Mamba Fusion + Multi-Head Regression\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, pretrained: bool = True,\n",
    "                 backbone_path: Optional[Path] = None):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.backbone_path = backbone_path\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, pretrained=pretrained, num_classes=0, global_pool=''\n",
    "        )\n",
    "        nf = self.backbone.num_features\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            LocalMambaBlock(nf, kernel_size=5, dropout=0.1),\n",
    "            LocalMambaBlock(nf, kernel_size=5, dropout=0.1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.head_green = nn.Sequential(\n",
    "            nn.Linear(nf, nf // 2), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(nf // 2, 1), nn.Softplus()\n",
    "        )\n",
    "        self.head_dead = nn.Sequential(\n",
    "            nn.Linear(nf, nf // 2), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(nf // 2, 1), nn.Softplus()\n",
    "        )\n",
    "        self.head_clover = nn.Sequential(\n",
    "            nn.Linear(nf, nf // 2), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(nf // 2, 1), nn.Softplus()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tuple (left, right)\n",
    "        if isinstance(x, tuple):\n",
    "            left, right = x\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a tuple of (left, right)\")\n",
    "\n",
    "        x_l = self.backbone(left)\n",
    "        x_r = self.backbone(right)\n",
    "        x_cat = torch.cat([x_l, x_r], dim=1)\n",
    "        x_fused = self.fusion(x_cat)\n",
    "        x_pool = self.pool(x_fused.transpose(1, 2)).flatten(1)\n",
    "\n",
    "        green = self.head_green(x_pool)\n",
    "        dead = self.head_dead(x_pool)\n",
    "        clover = self.head_clover(x_pool)\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "\n",
    "        # Return as a single tensor (batch, 5)\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d65ac",
   "metadata": {
    "papermill": {
     "duration": 0.003294,
     "end_time": "2026-01-18T05:25:15.275497",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.272203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Test Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba5e3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.282970Z",
     "iopub.status.busy": "2026-01-18T05:25:15.282761Z",
     "iopub.status.idle": "2026-01-18T05:25:15.291961Z",
     "shell.execute_reply": "2026-01-18T05:25:15.291350Z"
    },
    "papermill": {
     "duration": 0.014234,
     "end_time": "2026-01-18T05:25:15.292926",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.278692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset and transforms defined\n"
     ]
    }
   ],
   "source": [
    "class PastureImageTestDataset(Dataset):\n",
    "    \"\"\"Dataset for test images with metadata\"\"\"\n",
    "    def __init__(self, df, image_root, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_root / row[\"image_path\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = img.size  # expect (2000, 1000)\n",
    "\n",
    "        # Split in the middle (deterministic for test)\n",
    "        left = img.crop((0, 0, h, h))        # (0, 0, 1000, 1000)\n",
    "        right = img.crop((w - h, 0, w, h))   # (1000, 0, 2000, 1000)\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(left)\n",
    "            img2 = self.transform(right)\n",
    "\n",
    "        # Return images and row info\n",
    "        return (img1, img2), row.to_dict()\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "test_tfms = T.Compose([\n",
    "    T.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def get_tta_transforms():\n",
    "    \"\"\"Returns a list of transform pipelines for TTA during inference.\"\"\"\n",
    "    base_transforms = [\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "    # View 1: Original\n",
    "    original_view = T.Compose([\n",
    "        T.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 2: Horizontal Flip\n",
    "    hflip_view = T.Compose([\n",
    "        T.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "        T.RandomHorizontalFlip(p=1.0),\n",
    "        T.ToTensor(),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 3: Vertical Flip\n",
    "    vflip_view = T.Compose([\n",
    "        T.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "        T.RandomVerticalFlip(p=1.0),\n",
    "        T.ToTensor(),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 4: Rotate90\n",
    "    vflip_view = T.Compose([\n",
    "        T.Resize((CFG.IMG_SIZE, CFG.IMG_SIZE)),\n",
    "        T.Lambda(lambda img: T.functional.rotate(img, angle=90)),\n",
    "        T.ToTensor(),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    return [original_view, hflip_view, vflip_view]\n",
    "\n",
    "\n",
    "def collate_fn_test(batch):\n",
    "    \"\"\"Custom collate function for test data\"\"\"\n",
    "    imgs1, imgs2 = [], []\n",
    "    row_infos = []\n",
    "\n",
    "    for (img1, img2), row_info in batch:\n",
    "        imgs1.append(img1)\n",
    "        imgs2.append(img2)\n",
    "        row_infos.append(row_info)\n",
    "\n",
    "    imgs1 = torch.stack(imgs1)\n",
    "    imgs2 = torch.stack(imgs2)\n",
    "\n",
    "    return (imgs1, imgs2), row_infos\n",
    "\n",
    "\n",
    "print(\"Test dataset and transforms defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d13db4",
   "metadata": {
    "papermill": {
     "duration": 0.003348,
     "end_time": "2026-01-18T05:25:15.299618",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.296270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29264b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.307076Z",
     "iopub.status.busy": "2026-01-18T05:25:15.306644Z",
     "iopub.status.idle": "2026-01-18T05:25:15.311520Z",
     "shell.execute_reply": "2026-01-18T05:25:15.310762Z"
    },
    "papermill": {
     "duration": 0.009771,
     "end_time": "2026-01-18T05:25:15.312585",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.302814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_with_model(model, loader, use_tta=False):\n",
    "    \"\"\"\n",
    "    Make predictions with a single model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        test_loader: DataLoader for test data\n",
    "        use_tta: Whether to use test-time augmentation\n",
    "    \n",
    "    Returns:\n",
    "        predictions: numpy array of shape (n_samples, 5) with all 5 targets\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Standard inference without TTA\n",
    "    \n",
    "    preds_all = []\n",
    "    with torch.no_grad():\n",
    "        for (imgs1, imgs2), _ in tqdm(test_loader, desc=\"Inference\"):\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                pred = model((imgs1, imgs2))\n",
    "\n",
    "            preds_all.append(pred.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(preds_all)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ec5f8",
   "metadata": {
    "papermill": {
     "duration": 0.003301,
     "end_time": "2026-01-18T05:25:15.319339",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.316038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Inference with Model Ensemble\n",
    "\n",
    "Load one model at a time, make predictions, and ensemble the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69133798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:25:15.327247Z",
     "iopub.status.busy": "2026-01-18T05:25:15.327076Z",
     "iopub.status.idle": "2026-01-18T05:26:17.540045Z",
     "shell.execute_reply": "2026-01-18T05:26:17.539235Z"
    },
    "papermill": {
     "duration": 62.21848,
     "end_time": "2026-01-18T05:26:17.541528",
     "exception": false,
     "start_time": "2026-01-18T05:25:15.323048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loader created with 1 samples\n",
      "\n",
      "============================================================\n",
      "Processing Fold 0\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 1\n",
      "============================================================\n",
      "Loading model from /kaggle/input/biomass-model-dinov3/biomass_model_easy_fold1_0.6228.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 predictions shape: (1, 5)\n",
      "Predictions stats: min=0.4697, max=67.5009, mean=34.0756\n",
      "\n",
      "Memory cleaned after fold 1\n",
      "\n",
      "============================================================\n",
      "Processing Fold 2\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 3\n",
      "============================================================\n",
      "Loading model from /kaggle/input/biomass-model-dinov3/biomass_model_easy_fold3.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 predictions shape: (1, 5)\n",
      "Predictions stats: min=0.4221, max=70.7346, mean=36.0408\n",
      "\n",
      "Memory cleaned after fold 3\n",
      "\n",
      "============================================================\n",
      "All folds processed: 2 models\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = PastureImageTestDataset(\n",
    "    test_wide,\n",
    "    CFG.DATA_DIR,\n",
    "    test_tfms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn_test\n",
    ")\n",
    "\n",
    "print(f\"Test loader created with {len(test_dataset)} samples\")\n",
    "\n",
    "# Storage for ensemble predictions\n",
    "all_fold_predictions = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold in range(0, CFG.N_FOLDS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    model_file = (\n",
    "        \"biomass_model_easy_fold1_0.6228.pth\" if fold == 1 else\n",
    "        \"biomass_model_easy_fold3.pth\" if fold == 3 else\n",
    "        \"x\"\n",
    "    )\n",
    "    model_path = CFG.MODEL_DIR / model_file\n",
    "    if not os.path.exists(model_path):\n",
    "        continue\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    \n",
    "    model = BiomassModel(\n",
    "        model_name=CFG.BACKBONE,\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "    \n",
    "    # Handle DataParallel state dict\n",
    "    if list(state_dict.keys())[0].startswith('module.'):\n",
    "        # Remove 'module.' prefix\n",
    "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    fold_predictions = predict_with_model(\n",
    "        model, test_loader, use_tta=CFG.USE_TTA\n",
    "    )\n",
    "    weight = (\n",
    "        0.75 if fold == 1 else\n",
    "        1.25 if fold == 3 else\n",
    "        1.0\n",
    "    )\n",
    "    all_fold_predictions.append(weight * fold_predictions)\n",
    "    \n",
    "    print(f\"\\nFold {fold} predictions shape: {fold_predictions.shape}\")\n",
    "    print(f\"Predictions stats: min={fold_predictions.min():.4f}, max={fold_predictions.max():.4f}, mean={fold_predictions.mean():.4f}\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del model\n",
    "    del state_dict\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"\\nMemory cleaned after fold {fold}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"All folds processed: {len(all_fold_predictions)} models\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91984227",
   "metadata": {
    "papermill": {
     "duration": 0.003983,
     "end_time": "2026-01-18T05:26:17.549743",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.545760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6703391d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:26:17.558655Z",
     "iopub.status.busy": "2026-01-18T05:26:17.558415Z",
     "iopub.status.idle": "2026-01-18T05:26:17.564010Z",
     "shell.execute_reply": "2026-01-18T05:26:17.563352Z"
    },
    "papermill": {
     "duration": 0.011433,
     "end_time": "2026-01-18T05:26:17.565133",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.553700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble predictions shape: (1, 5)\n",
      "Ensemble stats: min=0.4399, max=69.5220, mean=35.3038\n",
      "\n",
      "First sample predictions:\n",
      "  Dry_Green_g: 37.0352\n",
      "  Dry_Dead_g: 32.0469\n",
      "  Dry_Clover_g: 0.4399\n",
      "  GDM_g: 37.4751\n",
      "  Dry_Total_g: 69.5220\n"
     ]
    }
   ],
   "source": [
    "# Average predictions across all folds\n",
    "if len(all_fold_predictions) == 0:\n",
    "    raise ValueError(\"No model predictions were generated. Check if model files exist.\")\n",
    "\n",
    "ensemble_predictions = np.mean(all_fold_predictions, axis=0)\n",
    "\n",
    "print(f\"Ensemble predictions shape: {ensemble_predictions.shape}\")\n",
    "print(f\"Ensemble stats: min={ensemble_predictions.min():.4f}, max={ensemble_predictions.max():.4f}, mean={ensemble_predictions.mean():.4f}\")\n",
    "\n",
    "# Show predictions for first sample\n",
    "print(\"\\nFirst sample predictions:\")\n",
    "for i, target in enumerate(CFG.TARGETS):\n",
    "    print(f\"  {target}: {ensemble_predictions[0, i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49bc61",
   "metadata": {
    "papermill": {
     "duration": 0.00389,
     "end_time": "2026-01-18T05:26:17.572978",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.569088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d03cacf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:26:17.581990Z",
     "iopub.status.busy": "2026-01-18T05:26:17.581522Z",
     "iopub.status.idle": "2026-01-18T05:26:17.593611Z",
     "shell.execute_reply": "2026-01-18T05:26:17.592856Z"
    },
    "papermill": {
     "duration": 0.017785,
     "end_time": "2026-01-18T05:26:17.594694",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.576909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission dataframe\n",
    "# Each test image should have 5 rows (one for each target)\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for idx, row in test_wide.iterrows():\n",
    "    image_id = row['image_path'].split('/')[-1].replace('.jpg', '')\n",
    "    \n",
    "    for target_idx, target_name in enumerate(CFG.TARGETS):\n",
    "        sample_id = f\"{image_id}__{target_name}\"\n",
    "        prediction = ensemble_predictions[idx, target_idx]\n",
    "        if target_name == \"Dry_Clover_g\":\n",
    "            prediction = prediction * 0.8\n",
    "        elif target_name == \"Dry_Dead_g\":\n",
    "            if prediction > 20:\n",
    "                prediction *= 1.1\n",
    "            elif prediction < 10:\n",
    "                prediction *= 0.9\n",
    "        \n",
    "        submission_rows.append({\n",
    "            'sample_id': sample_id,\n",
    "            'target': prediction\n",
    "        })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_path = \"submission.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4718a8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:26:17.603951Z",
     "iopub.status.busy": "2026-01-18T05:26:17.603570Z",
     "iopub.status.idle": "2026-01-18T05:26:17.618943Z",
     "shell.execute_reply": "2026-01-18T05:26:17.618358Z"
    },
    "papermill": {
     "duration": 0.021263,
     "end_time": "2026-01-18T05:26:17.619973",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.598710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission statistics by target:\n",
      "  Dry_Green_g:\n",
      "    Count: 1\n",
      "    Min: 37.0352\n",
      "    Max: 37.0352\n",
      "    Mean: 37.0352\n",
      "    Median: 37.0352\n",
      "  Dry_Dead_g:\n",
      "    Count: 1\n",
      "    Min: 35.2516\n",
      "    Max: 35.2516\n",
      "    Mean: 35.2516\n",
      "    Median: 35.2516\n",
      "  Dry_Clover_g:\n",
      "    Count: 1\n",
      "    Min: 0.3520\n",
      "    Max: 0.3520\n",
      "    Mean: 0.3520\n",
      "    Median: 0.3520\n",
      "  GDM_g:\n",
      "    Count: 1\n",
      "    Min: 37.4751\n",
      "    Max: 37.4751\n",
      "    Mean: 37.4751\n",
      "    Median: 37.4751\n",
      "  Dry_Total_g:\n",
      "    Count: 1\n",
      "    Min: 69.5220\n",
      "    Max: 69.5220\n",
      "    Mean: 69.5220\n",
      "    Median: 69.5220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>37.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>35.251563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>0.351952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>37.475098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>69.521973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0   ID1001187975__Dry_Green_g  37.035156\n",
       "1    ID1001187975__Dry_Dead_g  35.251563\n",
       "2  ID1001187975__Dry_Clover_g   0.351952\n",
       "3         ID1001187975__GDM_g  37.475098\n",
       "4   ID1001187975__Dry_Total_g  69.521973"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display statistics\n",
    "print(\"\\nSubmission statistics by target:\")\n",
    "for target in CFG.TARGETS:\n",
    "    target_rows = submission_df[submission_df['sample_id'].str.contains(target)]\n",
    "    print(f\"  {target}:\")\n",
    "    print(f\"    Count: {len(target_rows)}\")\n",
    "    print(f\"    Min: {target_rows['target'].min():.4f}\")\n",
    "    print(f\"    Max: {target_rows['target'].max():.4f}\")\n",
    "    print(f\"    Mean: {target_rows['target'].mean():.4f}\")\n",
    "    print(f\"    Median: {target_rows['target'].median():.4f}\")\n",
    "\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0f197",
   "metadata": {
    "papermill": {
     "duration": 0.004773,
     "end_time": "2026-01-18T05:26:17.629040",
     "exception": false,
     "start_time": "2026-01-18T05:26:17.624267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 9280423,
     "sourceId": 14533802,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 282128585,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 88.966464,
   "end_time": "2026-01-18T05:26:21.285385",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-18T05:24:52.318921",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
